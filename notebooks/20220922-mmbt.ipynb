{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像データとテキストデータの両方を同時に扱うことができるMMBTを用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まずはセッティング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## colabでこのノートを実行する時のみ使うセル\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !pip install transformers[ja]\n",
    "# !pip install --quiet sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.special import softmax\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, MMBTForClassification, MMBTConfig, AutoConfig,\n",
    "    Trainer, TrainingArguments,\n",
    ")\n",
    "import transformers\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import ResNet152_Weights, resnet152\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## colab上のパス\n",
    "#  INPUT = \"/content/drive/MyDrive/Nishika/bokete\"\n",
    "# train_image_path = \"/content/train/\"\n",
    "# test_image_path = \"/content/test/\"\n",
    "\n",
    "# ローカル上のパス \n",
    "INPUT = \"/Users/koshidatatsuo/python/nishika/bokete\"\n",
    "train_image_path = \"/content/train/\"\n",
    "test_image_path = \"/content/test/\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(INPUT, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(INPUT, \"test.csv\"))\n",
    "submission_df = pd.read_csv(os.path.join(INPUT, \"sample_submission.csv\"))\n",
    "\n",
    "train_df[\"img_path\"] = train_image_path + train_df[\"odai_photo_file_name\"]\n",
    "test_df[\"img_path\"] = test_image_path + test_df[\"odai_photo_file_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちゃんとデータが取得できているか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: (24962, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>odai_photo_file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>is_laugh</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ge5kssftl</td>\n",
       "      <td>9fkys1gb2r.jpg</td>\n",
       "      <td>君しょっちゅうソレ自慢するけど、ツムジ２個ってそんなに嬉しいのかい？</td>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/9fkys1gb2r.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r7sm6tvkj</td>\n",
       "      <td>c6ag0m1lak.jpg</td>\n",
       "      <td>これでバレない？授業中寝てもバレない？</td>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/c6ag0m1lak.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yp5aze0bh</td>\n",
       "      <td>whtn6gb9ww.jpg</td>\n",
       "      <td>「あなたも感じる？」\\n『ああ…、感じてる…』\\n「後ろに幽霊いるよね…」\\n『女のな…』</td>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/whtn6gb9ww.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ujaixzo56</td>\n",
       "      <td>6yk5cwmrsy.jpg</td>\n",
       "      <td>大塚愛聞いてたらお腹減った…さく、らんぼと牛タン食べたい…</td>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/6yk5cwmrsy.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7vkeveptl</td>\n",
       "      <td>0i9gsa2jsm.jpg</td>\n",
       "      <td>熊だと思ったら嫁だった</td>\n",
       "      <td>0</td>\n",
       "      <td>/content/train/0i9gsa2jsm.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id odai_photo_file_name  \\\n",
       "0  ge5kssftl       9fkys1gb2r.jpg   \n",
       "1  r7sm6tvkj       c6ag0m1lak.jpg   \n",
       "2  yp5aze0bh       whtn6gb9ww.jpg   \n",
       "3  ujaixzo56       6yk5cwmrsy.jpg   \n",
       "4  7vkeveptl       0i9gsa2jsm.jpg   \n",
       "\n",
       "                                            text  is_laugh  \\\n",
       "0             君しょっちゅうソレ自慢するけど、ツムジ２個ってそんなに嬉しいのかい？         0   \n",
       "1                            これでバレない？授業中寝てもバレない？         0   \n",
       "2  「あなたも感じる？」\\n『ああ…、感じてる…』\\n「後ろに幽霊いるよね…」\\n『女のな…』         0   \n",
       "3                 大塚愛聞いてたらお腹減った…さく、らんぼと牛タン食べたい…          0   \n",
       "4                                    熊だと思ったら嫁だった         0   \n",
       "\n",
       "                        img_path  \n",
       "0  /content/train/9fkys1gb2r.jpg  \n",
       "1  /content/train/c6ag0m1lak.jpg  \n",
       "2  /content/train/whtn6gb9ww.jpg  \n",
       "3  /content/train/6yk5cwmrsy.jpg  \n",
       "4  /content/train/0i9gsa2jsm.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data: (6000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>odai_photo_file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rfdjcfsqq</td>\n",
       "      <td>nc1kez326b.jpg</td>\n",
       "      <td>僕のママ、キャラ弁のゆでたまごに８時間かかったんだ</td>\n",
       "      <td>/content/test/nc1kez326b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tsgqmfpef</td>\n",
       "      <td>49xt2fmjw0.jpg</td>\n",
       "      <td>かわいいが作れた！</td>\n",
       "      <td>/content/test/49xt2fmjw0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>owjcthkz2</td>\n",
       "      <td>9dtscjmyfh.jpg</td>\n",
       "      <td>来世の志茂田景樹</td>\n",
       "      <td>/content/test/9dtscjmyfh.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rvgaocjyy</td>\n",
       "      <td>osa3n56tiv.jpg</td>\n",
       "      <td>ちょ、あの、オカン、これ水風呂やねんけど、なんの冗談??</td>\n",
       "      <td>/content/test/osa3n56tiv.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uxtwu5i69</td>\n",
       "      <td>yb1yqs4pvb.jpg</td>\n",
       "      <td>「今日は皆さんにザリガニと消防車の違いを知ってもらいたいと思います」『どっちも同じだろ。両方...</td>\n",
       "      <td>/content/test/yb1yqs4pvb.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id odai_photo_file_name  \\\n",
       "0  rfdjcfsqq       nc1kez326b.jpg   \n",
       "1  tsgqmfpef       49xt2fmjw0.jpg   \n",
       "2  owjcthkz2       9dtscjmyfh.jpg   \n",
       "3  rvgaocjyy       osa3n56tiv.jpg   \n",
       "4  uxtwu5i69       yb1yqs4pvb.jpg   \n",
       "\n",
       "                                                text  \\\n",
       "0                          僕のママ、キャラ弁のゆでたまごに８時間かかったんだ   \n",
       "1                                          かわいいが作れた！   \n",
       "2                                           来世の志茂田景樹   \n",
       "3                       ちょ、あの、オカン、これ水風呂やねんけど、なんの冗談??   \n",
       "4  「今日は皆さんにザリガニと消防車の違いを知ってもらいたいと思います」『どっちも同じだろ。両方...   \n",
       "\n",
       "                       img_path  \n",
       "0  /content/test/nc1kez326b.jpg  \n",
       "1  /content/test/49xt2fmjw0.jpg  \n",
       "2  /content/test/9dtscjmyfh.jpg  \n",
       "3  /content/test/osa3n56tiv.jpg  \n",
       "4  /content/test/yb1yqs4pvb.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"train_data: {train_df.shape}\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(f\"test_data: {test_df.shape}\")\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"is_laugh\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMBTとはMultiModal BiTransformersの略であり、BERTをベースとした画像とテキストのマルチモーダルディープラーニングです。画像にはResNet152を、テキスト側はBERTを用いてそれぞれベクトル変換し、両方をtokenとして連結したものに再度BERTに入力します。  \n",
    "https://arxiv.org/pdf/1909.02950.pdf\n",
    "\n",
    "https://github.com/facebookresearch/mmbt\n",
    "\n",
    "すでにhuggingface内にモデルがあるので、今回はこちらを使用していきたいと思います。\n",
    "https://huggingface.co/docs/transformers/main/en/model_summary#multimodal-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データをEmbeddingしていきます\n",
    "class ImageEncoder(nn.Module):\n",
    "    POOLING_BREAKDOWN = {1: (1, 1), 2: (2, 1), 3: (3, 1), 4: (2, 2), 5: (5, 1), 6: (3, 2), 7: (7, 1), 8: (4, 2), 9: (3, 3)}\n",
    "    def __init__(self, pretrained_weight):\n",
    "        super().__init__()\n",
    "        model = resnet152(weights=pretrained_weight)\n",
    "        modules = list(model.children())[:-2]\n",
    "        self.model = nn.Sequential(*modules)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(self.POOLING_BREAKDOWN[3])\n",
    "\n",
    "    def forward(self,  x):\n",
    "        out = self.pool(self.model(x))\n",
    "        out = torch.flatten(out, start_dim=2)\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jpg(path):\n",
    "    image_tensor = read_image(path)\n",
    "    if image_tensor.shape[0] == 1:\n",
    "        # 1channel=白黒画像があるので3channelにconvertしています。\n",
    "        image_tensor = image_tensor.expand(3, *image_tensor.shape[1:])\n",
    "    return image_tensor\n",
    "\n",
    "class BoketeTextImageDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_seq_len:int, image_transform):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.image_transforms = image_transform.transforms()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        sentence = torch.tensor(self.tokenizer.encode(row[\"text\"], max_length=self.max_seq_len, padding=\"max_length\", truncation=True))\n",
    "        start_token, sentence, end_token = sentence[0], sentence[1:-1], sentence[-1]\n",
    "        sentence = sentence[:self.max_seq_len]\n",
    "\n",
    "        image = self.image_transforms(read_jpg(row[\"img_path\"]))\n",
    "\n",
    "        return {\n",
    "            \"image_start_token\": start_token,\n",
    "            \"image_end_token\": end_token,\n",
    "            \"sentence\": sentence,\n",
    "            \"image\": image,\n",
    "            \"label\": torch.tensor(row[\"is_laugh\"]),\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    lens = [len(row[\"sentence\"]) for row in batch]\n",
    "    bsz, max_seq_len = len(batch), max(lens)\n",
    "\n",
    "    mask_tensor = torch.zeros(bsz, max_seq_len, dtype=torch.long)\n",
    "    text_tensor = torch.zeros(bsz, max_seq_len, dtype=torch.long)\n",
    "\n",
    "    for i_batch, (input_row, length) in enumerate(zip(batch, lens)):\n",
    "        text_tensor[i_batch, :length] = input_row[\"sentence\"]\n",
    "        mask_tensor[i_batch, :length] = 1\n",
    "\n",
    "    img_tensor = torch.stack([row[\"image\"] for row in batch])\n",
    "    tgt_tensor = torch.stack([row[\"label\"] for row in batch])\n",
    "    img_start_token = torch.stack([row[\"image_start_token\"] for row in batch])\n",
    "    img_end_token = torch.stack([row[\"image_end_token\"] for row in batch])\n",
    "\n",
    "    return {\n",
    "        \"input_ids\":text_tensor,\n",
    "        \"attention_mask\":mask_tensor,\n",
    "        \"input_modal\":img_tensor,\n",
    "        \"modal_start_tokens\":img_start_token,\n",
    "        \"modal_end_tokens\":img_end_token,\n",
    "        \"labels\":tgt_tensor,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済みモデルには、東北大学の乾研究室が作成したものを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_idx, val_idx = train_test_split(list(range(len(train_df))), test_size=0.2, random_state=42, stratify=train_df[\"is_laugh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = BoketeTextImageDataset(train_df.iloc[trn_idx], tokenizer, 48, image_transform=ResNet152_Weights.IMAGENET1K_V2)\n",
    "val_ds = BoketeTextImageDataset(train_df.iloc[val_idx], tokenizer, 48, image_transform=ResNet152_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = BoketeTextImageDataset(test_df, tokenizer, 48, image_transform=ResNet152_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MMBTConfig(transformer_config, num_labels=2)\n",
    "model = MMBTForClassification(config, transformer, ImageEncoder(ResNet152_Weights.IMAGENET1K_V2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.use_return_dict = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config = model.mmbt.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_args = TrainingArguments(\n",
    "    output_dir=\"/content/mmbt_exp01\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    logging_steps=50,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=12,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_accumulation_steps=20,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainer_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=trn_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習の開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = trainer.predict(val_ds).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "log_loss(val_ds.df[\"is_laugh\"].values, softmax(val_preds, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(val_ds.df[\"is_laugh\"].values, np.argmax(val_preds, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_conf_options = {\"normalize\": None,}\n",
    "_plot_options = {\n",
    "        \"cmap\": \"Blues\",\n",
    "        \"annot\": True\n",
    "    }\n",
    "\n",
    "conf = confusion_matrix(y_true=val_ds.df[\"is_laugh\"].values,\n",
    "                        y_pred=np.argmax(val_preds, axis=-1),\n",
    "                        **_conf_options)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(conf, ax=ax, **_plot_options)\n",
    "ax.set_ylabel(\"Label\")\n",
    "ax.set_xlabel(\"Predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(test_ds).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"is_laugh\"] = softmax(preds, axis=-1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"is_laugh\"] = submission_df[\"is_laugh\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## colab上で実行する時はこちらのパス\n",
    "#OUTPUT = \"/content/drive/MyDrive/Nishika/bokete\"\n",
    "\n",
    "OUTPUT = \"/Users/koshidatatsuo/python/nishika/bokete\" # ディレクトリを指定してください\n",
    "submission_df.to_csv(os.path.join(OUTPUT,'submission2.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fe9977627f3ca6d11c110215fba05053f59a783db248ce88310573a63e80709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
